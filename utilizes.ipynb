{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d89e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "import numpy as np\n",
    "from scipy.special import erf\n",
    "from scipy.stats import beta as beta_dist\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.interpolate import interp1d\n",
    "import bilby\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from bilby.core.prior import Uniform\n",
    "from bilby.core.sampler import run_sampler\n",
    "from bilby.core.prior import LogUniform\n",
    "from bilby.hyper.likelihood import HyperparameterLikelihood\n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "import random\n",
    "import argparse#\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import cupy as xp\n",
    "    from cupyx.scipy.special import erf, gammaln  # noqa\n",
    "\n",
    "    CUPY_LOADED = True\n",
    "except ImportError:\n",
    "    import numpy as xp\n",
    "    from scipy.special import erf, gammaln  # noqa\n",
    "\n",
    "    CUPY_LOADED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931664f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary:\n",
    "1######fundmental models\n",
    "###the structure of fundmental models\n",
    "#+uniform model\n",
    "#+log-uniform\n",
    "#+pow\n",
    "#+log-normal\n",
    "#+SST\n",
    "#+Gamma\n",
    "############\n",
    "2#####Gaussian distribution series models\n",
    "###the structure of Gaussian distribution series models\n",
    "#+Gaussian model \n",
    "#+Gaussian model with fixed maxmum and minimum mass\n",
    "#+Gaussian model with fixed min\n",
    "#+Gaussian model with fixed max\n",
    "############\n",
    "3##### 2-Gaussian distributions series\n",
    "###the structure of 2-Gaussian distribution series models\n",
    "#+2G with free paramaters maxmum and minimum mass \n",
    "#+2G fixed max\n",
    "#+2G fixed min\n",
    "#+2G fixed min and max\n",
    "############\n",
    "4#####3Gaussian distribution series\n",
    "###the structure of 3-Gaussian distribution series models\n",
    "#+3G fixed min and max\n",
    "############\n",
    "5#######turn on power-law model series\n",
    "###the structure of turn on power-law model series\n",
    "#+top\n",
    "#+top with fixed m_max\n",
    "#+top + G \n",
    "#+top + G with fixed m_max\n",
    "###############\n",
    "\n",
    "#begin uniform model\n",
    "def hyper_prior_U(dataset,mlo,mup):\n",
    "    return (( dataset['mu'] >= mlo) & (dataset['mu'] <= mup) ) / abs(mup-mlo)\n",
    "\n",
    "hp_priors_U = dict(mlo=Uniform(0.9, 1.5, 'mlo',r'$\\rm{m^l}$'),\n",
    "                mup=Uniform(1.5, 2.9, 'mup',r'$\\rm{m^u}$'))\n",
    "#end uniform model\n",
    "\n",
    "#begin log-uniform\n",
    "def hyper_prior_logu(dataset,mlo,mup):\n",
    "    return (( dataset['mu'] >= mlo) & (dataset['mu'] <= mup))/( dataset['mu'] * np.log(mup / mlo) )\n",
    "\n",
    "hp_priors_logu = dict(mlo=Uniform(0.9, 1.5, 'mlo',r'$\\rm{m^l}$'),\n",
    "                mup=Uniform(1.5, 2.9, 'mup',r'$\\rm{m^u}$'))\n",
    "#end log-uniform\n",
    "\n",
    "#begin pow\n",
    "def hyper_prior_pow(dataset,mlo,mup,beta):\n",
    "    beta=-1*beta\n",
    "    return (( dataset['mu'] >= mlo) & (dataset['mu'] <= mup))*((1+beta)/(mup**(1+beta)-mlo**(1+beta)))*dataset['mu']**beta\n",
    "\n",
    "hp_priors_pow = dict(mlo=Uniform(0.9, 1.5, 'mlo',r'$\\rm{m^l}$'),\n",
    "                mup=Uniform(1.5, 2.9, 'mup',r'$\\rm{m^u}$'),\n",
    "                beta=Uniform(-5, 25, 'beta','$\\\\beta$'))\n",
    "#end pow\n",
    "\n",
    "#begin log-normal\n",
    "def hyper_prior_lognorm(dataset, s_mu, s_sigma):\n",
    "    return np.exp(- (np.log(dataset['mu']) - s_mu)**2 / (2 * s_sigma**2)) /\\\n",
    "        (2 * np.pi * s_sigma**2)**0.5/(dataset['mu'])\n",
    "hp_priors_lognorm = dict(s_mu=Uniform(0.01, 1, 's_mu', '$\\mu$'),\n",
    "                 s_sigma=Uniform(0.01, 0.5, 's_sigma', '$\\sigma$') )\n",
    "#end log-normal\n",
    "\n",
    "#begin SST\n",
    "from scipy.special import beta\n",
    "def hyper_prior_sst(dataset, mu,sigma,nu,tau):\n",
    "        c = 2 * nu * ((1 + nu ** 2) *\n",
    "                                beta(0.5, tau / 2) *\n",
    "                                tau ** 0.5) ** -1\n",
    "        m = ((2 * tau ** 0.5) * (nu - nu ** -1)) / (\n",
    "                (tau - 1) * beta(0.5, 0.5 * tau))\n",
    "        s2 = ((tau / (tau - 2)) * (\n",
    "                nu ** 2 + nu ** -2 - 1) - m ** 2)\n",
    "        mu_0 = mu - (sigma * m / np.sqrt(s2))\n",
    "        sigma_0 = sigma / np.sqrt(s2)\n",
    "        z = (dataset['mu'] - mu_0) / sigma_0\n",
    "        p = np.where(dataset['mu'] < mu_0,\n",
    "                     (c / sigma_0) * (1 + ((nu ** 2) * (z ** 2)) / tau) ** (\n",
    "                             -(tau + 1) / 2),\n",
    "                     (c / sigma_0) * (1 + (z ** 2) / ((nu ** 2) * tau)) ** (\n",
    "                             -(tau + 1) / 2))\n",
    "        return p\n",
    "\n",
    "hp_priors_sst = dict(mu=Uniform(0.9, 2.9, 'mlo',r'$\\rm{m^l}$'),\n",
    "                sigma=Uniform(0.01, 2, 'sigma',r'$\\rm{m^u}$'),\n",
    "                nu=Uniform(0,8,'nu'),\n",
    "                   tau=Uniform(2.001,20,'tau') )\n",
    "#end SST\n",
    "\n",
    "#begin gamma distribution\n",
    "from scipy.special import beta\n",
    "from scipy.special import gamma\n",
    "def hyper_prior_gamma(dataset, k,theta):\n",
    "    return (1 / (gamma(k)*theta**k)) * dataset['mu']**(k-1) *np.exp(-dataset['mu']/theta)\n",
    "\n",
    "hp_priors_gamma = dict(k=Uniform(0, 80, 'k',r'$k$'),\n",
    "                theta=Uniform(0.01, 0.1, 'theta',r'$\\theta$') )\n",
    "#end gamma distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fbe13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Gaussian distribution series models\n",
    "###the structure of Gaussian distribution series models\n",
    "#+Gaussian model \n",
    "#+Gaussian model with fixed maxmum and minimum mass\n",
    "#+Gaussian model with fixed min\n",
    "#+Gaussian model with fixed max\n",
    "############\n",
    "\n",
    "#begin Gaussian model \n",
    "def hyper_prior_G(dataset, mu, sigma,mlo,mup):\n",
    "    normalisingTerm = 0.5 * ( erf((mu-mlo)/(np.sqrt(2) * sigma)) -  erf((mu-mup)/(np.sqrt(2) * sigma)) )\n",
    "    return ( ( dataset['mu'] >= mlo) & (dataset['mu'] <= mup))*((mu>mlo)&(mu<mup)) * (np.exp(- (dataset['mu'] - mu)**2 / (2 * sigma**2)) /\\\n",
    "        (2 * np.pi * sigma**2)**0.5) / normalisingTerm \n",
    "hp_priors_G = dict(mu=Uniform(0.9, 2.9, 's_mu', '$\\mu$'),\n",
    "                 sigma=Uniform(0.01, 2, 's_sigma', '$\\sigma$'),\n",
    "                 mlo=Uniform(0.9, 1.5, 'mlow', '$mlow$'),\n",
    "                 mup=Uniform(1.5, 2.9, 'mup', '$mup$')\n",
    "                              )\n",
    "#end Gaussian model \n",
    "\n",
    "#begin Gaussian model with fixed upper and lower mass\n",
    "def hyper_prior_G_fixed_max_min(dataset, mu, sigma):\n",
    "    mup=2.9\n",
    "    mlo=0.9\n",
    "    normalisingTerm = 0.5 * ( erf((mu-mlo)/(np.sqrt(2) * sigma)) -  erf((mu-mup)/(np.sqrt(2) * sigma)) )\n",
    "    return ( ( dataset['mu'] >= mlo) & (dataset['mu'] <= mup))*((mu>mlo)&(mu<mup)) * (np.exp(- (dataset['mu'] - mu)**2 / (2 * sigma**2)) /\\\n",
    "        (2 * np.pi * sigma**2)**0.5) / normalisingTerm \n",
    "hp_priors_G_fixed_max_min= dict(mu=Uniform(0.9, 2.9, 's_mu', '$\\mu$'),\n",
    "                 sigma=Uniform(0.01, 2, 's_sigma', '$\\sigma$'))\n",
    "#end Gaussian with fixed upper and lower mass\n",
    "\n",
    "#begin Gaussian model with fixed min\n",
    "def hyper_prior_G_fixed_min(dataset, mu, sigma,mup):\n",
    "    mlo=0.9\n",
    "    normalisingTerm = 0.5 * ( erf((mu-mlo)/(np.sqrt(2) * sigma)) -  erf((mu-mup)/(np.sqrt(2) * sigma)) )\n",
    "    return ( ( dataset['mu'] >= mlo) & (dataset['mu'] <= mup))*((mu>mlo)&(mu<mup)) * (np.exp(- (dataset['mu'] - mu)**2 / (2 * sigma**2)) /\\\n",
    "        (2 * np.pi * sigma**2)**0.5) / normalisingTerm \n",
    "hp_priors_G_fixed_min= dict(mu=Uniform(0.9, 2.9, 's_mu', '$\\mu$'),\n",
    "                 sigma=Uniform(0.01, 2, 's_sigma', '$\\sigma$'),\n",
    "                      mup=Uniform(1.5, 2.9, 'mup', '$mup$')     )\n",
    "#end Gaussian with fixed upper and lower mass\n",
    "\n",
    "#begin Gaussian model with fixed max\n",
    "def hyper_prior_G_fixed_max(dataset, mu, sigma,mlo):\n",
    "    mup=2.9\n",
    "    normalisingTerm = 0.5 * ( erf((mu-mlo)/(np.sqrt(2) * sigma)) -  erf((mu-mup)/(np.sqrt(2) * sigma)) )\n",
    "    return ( ( dataset['mu'] >= mlo) & (dataset['mu'] <= mup))*((mu>mlo)&(mu<mup)) * (np.exp(- (dataset['mu'] - mu)**2 / (2 * sigma**2)) /\\\n",
    "        (2 * np.pi * sigma**2)**0.5) / normalisingTerm \n",
    "hp_priors_G_fixed_max= dict(mu=Uniform(0.9, 2.9, 's_mu', '$\\mu$'),\n",
    "                 sigma=Uniform(0.01, 2, 's_sigma', '$\\sigma$'),\n",
    "                      mlo=Uniform(0.9, 1.5, 'mlow', '$mlow$')     )\n",
    "#end Gaussian with fixed upper and lower mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c15eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2-Gaussian distributions series\n",
    "###the structure of 2-Gaussian distribution series models\n",
    "#+2G with free paramaters maxmum and minimum mass \n",
    "#+2G fixed max\n",
    "#+2G fixed min\n",
    "#+2G fixed min and max\n",
    "############\n",
    "\n",
    "#2G with free paramaters maxmum and minimum mass \n",
    "def hyper_prior_2G(dataset, mu1, sigma1,mu2,sigma2,alpha,mup,mlo):\n",
    "    normalisingTerm1 = 0.5 * ( erf((mu1-mlo)/(np.sqrt(2) * sigma1)) -  erf((mu1-mup)/(np.sqrt(2) * sigma1)) )\n",
    "    normalisingTerm2 = 0.5 * ( erf((mu2-mlo)/(np.sqrt(2) * sigma2)) -  erf((mu2-mup)/(np.sqrt(2) * sigma2)) )\n",
    "    return ((mu2 < mup ) & (mu1 > mlo) & (mu1 < mu2)  & ( dataset['mu'] >= mlo) & (dataset['mu'] <= mup)) *\\\n",
    "        ( (( alpha*(np.exp(- (dataset['mu'] - mu1)**2 / (2 * sigma1**2)) /(2 * np.pi * sigma1**2)**0.5)) /normalisingTerm1) +\\\n",
    "        (1-alpha)*( ((np.exp(- (dataset['mu'] - mu2)**2 / (2 * sigma2**2)) /(2 * np.pi * sigma2**2)**0.5) ) / normalisingTerm2) )\n",
    "hp_priors_2G = dict(mu1=Uniform(0.9, 2.9, 'mu1', '$\\mu_1$'),\n",
    "                 sigma1=Uniform(0.01, 2, 'sigma1', '$\\sigma_1$'),\n",
    "                mu2=Uniform(0.9, 2.9, 'mu2', '$\\mu_2$'),\n",
    "                sigma2=Uniform(0.01, 2, 'sigma2', '$\\sigma_2$'),\n",
    "                alpha=Uniform(0.01, 1, 'alpha', '$\\\\alpha$'),\n",
    "                mup=Uniform(1.5, 2.9, 'mup',r'$\\rm{m^u}$'),\n",
    "                mlo=Uniform(0.9, 1.5, 'mlo',r'$\\rm{m^l}$') )\n",
    "#end 2G with free paramaters maxmum and minimum mass \n",
    "\n",
    "#2G fixed max\n",
    "def hyper_prior_2G_fixed_max(dataset, mu1, sigma1,mu2,sigma2,alpha,mlo):\n",
    "    mup=2.9\n",
    "    normalisingTerm1 = 0.5 * ( erf((mu1-mlo)/(np.sqrt(2) * sigma1)) -  erf((mu1-mup)/(np.sqrt(2) * sigma1)) )\n",
    "    normalisingTerm2 = 0.5 * ( erf((mu2-mlo)/(np.sqrt(2) * sigma2)) -  erf((mu2-mup)/(np.sqrt(2) * sigma2)) )\n",
    "    return ( (mu2 < mup ) & (mu1 > mlo) & (mu1 < mu2)  & ( dataset['mu'] >= mlo) & (dataset['mu'] <= mup)) *\\\n",
    "        ( (( alpha*(np.exp(- (dataset['mu'] - mu1)**2 / (2 * sigma1**2)) /(2 * np.pi * sigma1**2)**0.5)) /normalisingTerm1) +\\\n",
    "        (1-alpha)*( ((np.exp(- (dataset['mu'] - mu2)**2 / (2 * sigma2**2)) /(2 * np.pi * sigma2**2)**0.5) ) / normalisingTerm2) )\n",
    "hp_priors_2G_fixed_max = dict(mu1=Uniform(0.9, 2.9, 'mu1', '$\\mu_1$'),\n",
    "                 sigma1=Uniform(0.01, 2, 'sigma1', '$\\sigma_1$'),\n",
    "                mu2=Uniform(0.9, 2.9, 'mu2', '$\\mu_2$'),\n",
    "                sigma2=Uniform(0.01, 2, 'sigma2', '$\\sigma_2$'),\n",
    "                alpha=Uniform(0.01, 1, 'alpha', '$\\\\alpha$'),\n",
    "                mlo=Uniform(0.9, 1.5, 'mlo',r'$\\rm{m^l}$') )\n",
    "#end 2G fixed max\n",
    "\n",
    "#begin 2G fixed min\n",
    "def hyper_prior_2G_fixed_min(dataset, mu1, sigma1,mu2,sigma2,alpha,mup):\n",
    "    mlo=0.9\n",
    "    normalisingTerm1 = 0.5 * ( erf((mu1-mlo)/(np.sqrt(2) * sigma1)) -  erf((mu1-mup)/(np.sqrt(2) * sigma1)) )\n",
    "    normalisingTerm2 = 0.5 * ( erf((mu2-mlo)/(np.sqrt(2) * sigma2)) -  erf((mu2-mup)/(np.sqrt(2) * sigma2)) )\n",
    "    return ((mu2 < mup ) & (mu1 > mlo) & (mu1 < mu2)  & ( dataset['mu'] >= mlo) & (dataset['mu'] <= mup)) *\\\n",
    "        ( (( alpha*(np.exp(- (dataset['mu'] - mu1)**2 / (2 * sigma1**2)) /(2 * np.pi * sigma1**2)**0.5)) /normalisingTerm1) +\\\n",
    "        (1-alpha)*( ((np.exp(- (dataset['mu'] - mu2)**2 / (2 * sigma2**2)) /(2 * np.pi * sigma2**2)**0.5) ) / normalisingTerm2) )\n",
    "hp_priors_2G_fixed_min = dict(mu1=Uniform(0.9, 2.9, 'mu1', '$\\mu_1$'),\n",
    "                 sigma1=Uniform(0.01, 2, 'sigma1', '$\\sigma_1$'),\n",
    "                mu2=Uniform(0.9, 2.9, 'mu2', '$\\mu_2$'),\n",
    "                sigma2=Uniform(0.01, 2, 'sigma2', '$\\sigma_2$'),\n",
    "                alpha=Uniform(0.01, 1, 'alpha', '$\\\\alpha$'),\n",
    "                mup=Uniform(1.5, 2.9, 'mup',r'$\\rm{m^u}$') )\n",
    "#end 2G fixed min\n",
    "\n",
    "\n",
    "#begin two-Gausssian model with fixed max and min mass\n",
    "def hyper_prior_2G_fixed_max_min(dataset, mu1, sigma1,mu2,sigma2,alpha):\n",
    "    mup=2.9\n",
    "    mlo=0.9\n",
    "    normalisingTerm1 = 0.5 * ( erf((mu1-mlo)/(np.sqrt(2) * sigma1)) -  erf((mu1-mup)/(np.sqrt(2) * sigma1)) )\n",
    "    normalisingTerm2 = 0.5 * ( erf((mu2-mlo)/(np.sqrt(2) * sigma2)) -  erf((mu2-mup)/(np.sqrt(2) * sigma2)) )\n",
    "    return ((mu2 < mup ) & (mu1 > mlo) & (mu1 < mu2)  & ( dataset['mu'] >= mlo) & (dataset['mu'] <= mup)) *\\\n",
    "        ( (( alpha*(np.exp(- (dataset['mu'] - mu1)**2 / (2 * sigma1**2)) /(2 * np.pi * sigma1**2)**0.5)) /normalisingTerm1) +\\\n",
    "        (1-alpha)*( ((np.exp(- (dataset['mu'] - mu2)**2 / (2 * sigma2**2)) /(2 * np.pi * sigma2**2)**0.5) ) / normalisingTerm2) )\n",
    "hp_priors_2G_fixed_max_min = dict(mu1=Uniform(0.9, 2.9, 'mu1', '$\\mu_1$'),\n",
    "                 sigma1=Uniform(0.01, 2, 'sigma1', '$\\sigma_1$'),\n",
    "                mu2=Uniform(0.9, 2.9, 'mu2', '$\\mu_2$'),\n",
    "                sigma2=Uniform(0.01, 2, 'sigma2', '$\\sigma_2$'),\n",
    "                alpha=Uniform(0.01, 1, 'alpha', '$\\\\alpha$'))\n",
    "#end two-Gausssian model with fixed lower and upper mass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c312e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####3Gaussian distribution series\n",
    "###the structure of 3-Gaussian distribution series models\n",
    "#+3G fixed min and max\n",
    "############\n",
    "\n",
    "#begin three Gausssian model with fixed lower and upper mass\n",
    "def hyper_prior_3G_fixed_max_min(dataset, mu1, sigma1,mu2,sigma2,alpha,mu3,sigma3,beta):\n",
    "    mup=2.9\n",
    "    mlo=0.9\n",
    "    normalisingTerm1 = 0.5 * ( erf((mu1-mlo)/(np.sqrt(2) * sigma1)) -  erf((mu1-mup)/(np.sqrt(2) * sigma1)) )\n",
    "    normalisingTerm2 = 0.5 * ( erf((mu2-mlo)/(np.sqrt(2) * sigma2)) -  erf((mu2-mup)/(np.sqrt(2) * sigma2)) )\n",
    "    normalisingTerm3 = 0.5 * ( erf((mu3-mlo)/(np.sqrt(2) * sigma3)) -  erf((mu3-mup)/(np.sqrt(2) * sigma3)) )\n",
    "    if mu1 < mu2 and mu3>mu2  and alpha+beta<=1:\n",
    "        return ((alpha*(np.exp(- (dataset['mu'] - mu1)**2 / (2 * sigma1**2)) /(2 * np.pi * sigma1**2)**0.5))/normalisingTerm1)\\\n",
    "        +((beta*(np.exp(- (dataset['mu'] - mu2)**2 / (2 * sigma2**2)) /(2 * np.pi * sigma2**2)**0.5))/normalisingTerm2)\\\n",
    "        +(((1-alpha-beta)*(np.exp(- (dataset['mu'] - mu3)**2 / (2 * sigma3**2)) /(2 * np.pi * sigma3**2)**0.5))/normalisingTerm3)\n",
    "    else:\n",
    "        return 0\n",
    "hp_priors_3G_fixed_max_min = dict(mu1=Uniform(0.9, 2.9, 'mu1', '$\\mu_1$'),\n",
    "                 sigma1=Uniform(0.01, 2, 'sigma1', '$\\sigma_1$'),\n",
    "                mu2=Uniform(0.9, 2.9, 'mu2', '$\\mu_2$'),\n",
    "                sigma2=Uniform(0.01, 2, 'sigma2', '$\\sigma_2$'),\n",
    "                alpha=Uniform(0.01, 1, 'alpha', '$\\\\alpha$'),\n",
    "                mu3=Uniform(0.9, 2.9, 'mu3', '$\\mu_3$'),\n",
    "                sigma3=Uniform(0.01, 2, 'sigma3', '$\\sigma_3$'),\n",
    "                beta=Uniform(0.01, 1, 'beta', '$\\\\beta$'))\n",
    "#end three Gausssian model with fixed lower and upper mass\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8f71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######turn on power-law model series\n",
    "###the structure of turn on power-law model series\n",
    "#+top\n",
    "#+top with fixed m_max\n",
    "#+top + G \n",
    "#+top + G with fixed m_max\n",
    "###############\n",
    "\n",
    "#begin turn_on_pow \n",
    "def window(masses, mmin, mmax, delta_m):\n",
    "\n",
    "    \"\"\"\n",
    "    Apply a one sided window between mmin and mmin + delta_m to the\n",
    "    mass pdf.\n",
    "    The upper cut off is a step function,\n",
    "    the lower cutoff is a logistic rise over delta_m solar masses.\n",
    "    See T&T18 Eqs 7-8\n",
    "    Note that there is a sign error in that paper.\n",
    "    S = (f(m - mmin, delta_m) + 1)^{-1}\n",
    "    f(m') = delta_m / m' + delta_m / (m' - delta_m)\n",
    "    See also, https://en.wikipedia.org/wiki/Window_function#Planck-taper_window\n",
    "    \"\"\"\n",
    "    window = xp.ones_like(masses)\n",
    "    if delta_m > 0.0:\n",
    "        smoothing_region = (masses >= mmin) & (masses < (mmin + delta_m))\n",
    "        shifted_mass = masses[smoothing_region] - mmin\n",
    "        if shifted_mass.size:\n",
    "            exponent = xp.nan_to_num(\n",
    "                delta_m / shifted_mass + delta_m / (shifted_mass - delta_m)\n",
    "            )\n",
    "            window[smoothing_region] = 1 / (xp.exp(exponent) + 1)\n",
    "    window[(masses < mmin) | (masses > mmax)] = 0\n",
    "    return window    \n",
    "\n",
    "def extract_mass_parameters(parameters):\n",
    "    \"\"\"extract the parameters of the mass distribution hyperparameters used in\n",
    "    T&T18 from either a list or dictionary.\"\"\"\n",
    "    if isinstance(parameters, list):\n",
    "        return parameters\n",
    "    elif isinstance(parameters, dict):\n",
    "        keys = ['alpha', 'mmin', 'mmax', 'delta_m']\n",
    "        return [parameters[key] for key in keys]\n",
    "\n",
    "def ppow(masses, parameters):\n",
    "    \"\"\"1d unnormalised powerlaw mass probability with smoothed low-mass end\"\"\"\n",
    "    alpha, mmin, mmax, delta_m = extract_mass_parameters(parameters)\n",
    "    return masses**(-alpha) * window(masses, mmin, mmax, delta_m) \n",
    "\n",
    "def norm_ppow(parameters):\n",
    "    \"\"\"normalise ppow, requires m1s, an array of m values, and dm, the spacing of\n",
    "    that array\"\"\"\n",
    "    m1s = np.linspace(0.9, 2.9, 500)\n",
    "    return np.trapz(ppow(m1s, parameters), m1s)\n",
    "\n",
    "def turn_on_pow(masses, parameters, pow_norm):\n",
    "    alpha, mmin, mmax, delta_m = extract_mass_parameters(parameters)\n",
    "    p_pow = ppow(masses, parameters) / pow_norm\n",
    "    return  p_pow \n",
    "\n",
    "def hyper_prior_turn_on_pow(dataset, alpha, mmin, mmax, delta_m):\n",
    "    parameters = dict(\n",
    "        alpha=alpha, mmin=mmin, mmax=mmax, delta_m=delta_m)\n",
    "    pow_norm = norm_ppow(parameters)\n",
    "    probability = turn_on_pow(dataset['mu'], parameters, pow_norm)\n",
    "    return probability\n",
    "\n",
    "hp_priors_turn_on_pow= dict(alpha=Uniform(-5, 25, 'alpha', '$\\\\alpha$'),\n",
    "                 mmin=Uniform(0.9, 1.5, 'mmin', '$mmin$'),\n",
    "                mmax=Uniform(1.5, 2.9, 'mmax', '$mmax$'),\n",
    "                delta_m=Uniform(0.01, 1, 'delta', '$\\\\delta$'))\n",
    "#end turn_on_pow \n",
    "\n",
    "#begin turn_on_pow with fixed m_max\n",
    "def window_fix(masses, mmin,  delta_m):\n",
    "    mmaxs_fix=2.9\n",
    "    mmax=mmaxs_fix\n",
    "\n",
    "    \"\"\"\n",
    "    Apply a one sided window between mmin and mmin + delta_m to the\n",
    "    mass pdf.\n",
    "    The upper cut off is a step function,\n",
    "    the lower cutoff is a logistic rise over delta_m solar masses.\n",
    "    See T&T18 Eqs 7-8\n",
    "    Note that there is a sign error in that paper.\n",
    "    S = (f(m - mmin, delta_m) + 1)^{-1}\n",
    "    f(m') = delta_m / m' + delta_m / (m' - delta_m)\n",
    "    See also, https://en.wikipedia.org/wiki/Window_function#Planck-taper_window\n",
    "    \"\"\"\n",
    "    window_fix = xp.ones_like(masses)\n",
    "    if delta_m > 0.0:\n",
    "        smoothing_region = (masses >= mmin) & (masses < (mmin + delta_m))\n",
    "        shifted_mass = masses[smoothing_region] - mmin\n",
    "        if shifted_mass.size:\n",
    "            exponent = xp.nan_to_num(\n",
    "                delta_m / shifted_mass + delta_m / (shifted_mass - delta_m)\n",
    "            )\n",
    "            window_fix[smoothing_region] = 1 / (xp.exp(exponent) + 1)\n",
    "    window_fix[(masses < mmin) | (masses > mmax)] = 0\n",
    "    return window_fix    \n",
    "\n",
    "def extract_mass_parameters_fix(parameters):\n",
    "    \"\"\"extract the parameters of the mass distribution hyperparameters used in\n",
    "    T&T18 from either a list or dictionary.\"\"\"\n",
    "    if isinstance(parameters, list):\n",
    "        return parameters\n",
    "    elif isinstance(parameters, dict):\n",
    "        keys = ['alpha', 'mmin',  'delta_m']\n",
    "        return [parameters[key] for key in keys]\n",
    "\n",
    "def ppow_fix(masses, parameters):\n",
    "    \"\"\"1d unnormalised powerlaw mass probability with smoothed low-mass end\"\"\"\n",
    "    alpha, mmin,  delta_m = extract_mass_parameters_fix(parameters)\n",
    "    return masses**(-alpha) * window_fix(masses, mmin, delta_m) \n",
    "\n",
    "def norm_ppow_fix(parameters):\n",
    "    \"\"\"normalise ppow, requires m1s, an array of m values, and dm, the spacing of\n",
    "    that array\"\"\"\n",
    "    m1s = np.linspace(0.9, 2.9, 500)\n",
    "    return np.trapz(ppow_fix(m1s, parameters), m1s)\n",
    "\n",
    "def turn_on_pow_fix(masses, parameters, pow_norm_fix):\n",
    "    alpha, mmin, delta_m = extract_mass_parameters_fix(parameters)\n",
    "    p_pow_fix = ppow_fix(masses, parameters) / pow_norm_fix\n",
    "    return  p_pow_fix \n",
    "\n",
    "def hyper_prior_turn_on_pow_fix(dataset, alpha, mmin, delta_m):\n",
    "    parameters = dict(alpha=alpha, mmin=mmin, delta_m=delta_m)\n",
    "    pow_norm_fix = norm_ppow_fix(parameters)\n",
    "    probability_fix = turn_on_pow_fix(dataset['mu'], parameters, pow_norm_fix)\n",
    "    return probability_fix\n",
    "\n",
    "hp_priors_turn_on_pow_fix= dict(alpha=Uniform(-5, 25, 'alpha', '$\\\\alpha$'),\n",
    "                 mmin=Uniform(0.9, 1.5, 'mmin', '$mmin$'),\n",
    "                delta_m=Uniform(0.01, 1, 'delta', '$\\\\delta$'))\n",
    "#end turn_on_pow fixed m_max\n",
    "\n",
    "\n",
    "#begin top + Gaussian with fixed max    \n",
    "def hyper_prior_turn_on_pow_G_fixed_max(dataset, alpha, mmin, lam, mpp, sigpp, delta_m):\n",
    "    \"\"\"\n",
    "    Identically and independently masses following p(m1) in T&T 2018\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: dict\n",
    "        Dictionary containing NxM arrays, m1_source and m2_source\n",
    "    alpha, mmin, mmax, lam, mpp, sigpp, delta_m: see mass_distribution\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    probability: array-like\n",
    "        Probability of m1, m2 in dataset, shape=(NxM)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The factor of 2 comes from requiring m1>m2\n",
    "    \"\"\"\n",
    "    parameters = dict(alpha=alpha, mmin=mmin, lam=lam, mpp=mpp, sigpp=sigpp, delta_m=delta_m)\n",
    "    pow_norm_fixed_max = norm_ppow_topG_fixed_max(parameters)\n",
    "    pp_norm_fixed_max = norm_pnorm_topG_fixed_max(parameters)\n",
    "    probability = pmodel1d_topG_fixed_max(dataset['mu'], parameters, pow_norm_fixed_max, pp_norm_fixed_max)\n",
    "    return probability\n",
    "\n",
    "def pmodel1d_topG_fixed_max(ms, parameters, pow_norm_fixed_max, pp_norm_fixed_max):\n",
    "    \"\"\"normalised m1 pdf from T&T 2018\"\"\"\n",
    "    al, mn, lam, mp, sp, delta_m = extract_mass_parameters_topG_fixed_max(parameters)\n",
    "    p_pow_fixed_max = ppow_topG_fixed_max(ms, parameters) / pow_norm_fixed_max\n",
    "    p_norm_fixed_max = pnorm_topG_fixed_max(ms, parameters) / pp_norm_fixed_max\n",
    "    return (1 - lam) * p_pow_fixed_max + lam * p_norm_fixed_max\n",
    "\n",
    "def ppow_topG_fixed_max(ms, parameters):\n",
    "    \"\"\"1d unnormalised powerlaw mass probability with smoothed low-mass end\"\"\"\n",
    "    al, mn, lam, mp, sp, delta_m = extract_mass_parameters_topG_fixed_max(parameters)\n",
    "    return ms**(-al) * window_topG_fixed_max(ms, mn, delta_m)\n",
    "\n",
    "def norm_ppow_topG_fixed_max(parameters):\n",
    "    \"\"\"normalise ppow, requires m1s, an array of m values, and dm, the spacing of\n",
    "    that array\"\"\"\n",
    "    m1s = np.linspace(0.9, 2.9, 500)\n",
    "    return np.trapz(ppow_topG_fixed_max(m1s, parameters), m1s)\n",
    "\n",
    "\n",
    "def pnorm_topG_fixed_max(ms, parameters):\n",
    "    \"\"\"1d unnormalised normal distribution with low-mass smoothing\"\"\"\n",
    "    al, mn, lam, mp, sp, delta_m = extract_mass_parameters_topG_fixed_max(parameters)\n",
    "    return np.exp(-(ms - mp)**2 / (2 * sp**2)) * window_topG_fixed_max(ms, mn, delta_m)*(mp > (mn + delta_m) )\n",
    "\n",
    "\n",
    "def norm_pnorm_topG_fixed_max(parameters):\n",
    "    \"\"\"normalise pnorm, requires m1s, an array of m values, and dm, the spacing of\n",
    "    that array\"\"\"\n",
    "    m1s = np.linspace(0.9, 2.9, 500)\n",
    "    return np.trapz(pnorm_topG_fixed_max(m1s, parameters), m1s)\n",
    "\n",
    "def window_topG_fixed_max(ms, mn, delta_m):\n",
    "    mmaxs_topG=2.9  \n",
    "    mx=mmaxs_topG\n",
    "\n",
    "    \"\"\"\n",
    "    Apply a one sided window between mmin and mmin + delta_m to the\n",
    "    mass pdf.\n",
    "    The upper cut off is a step function,\n",
    "    the lower cutoff is a logistic rise over delta_m solar masses.\n",
    "    See T&T18 Eqs 7-8\n",
    "    Note that there is a sign error in that paper.\n",
    "    S = (f(m - mmin, delta_m) + 1)^{-1}\n",
    "    f(m') = delta_m / m' + delta_m / (m' - delta_m)\n",
    "    See also, https://en.wikipedia.org/wiki/Window_function#Planck-taper_window\n",
    "    \"\"\"\n",
    "    window_topG_fixed_max = xp.ones_like(ms)\n",
    "    if delta_m > 0.0:\n",
    "        smoothing_region = (ms >= mn) & (ms < (mn + delta_m))\n",
    "        shifted_mass = ms[smoothing_region] - mn\n",
    "        if shifted_mass.size:\n",
    "            exponent = xp.nan_to_num(\n",
    "                delta_m / shifted_mass + delta_m / (shifted_mass - delta_m)\n",
    "            )\n",
    "            window_topG_fixed_max[smoothing_region] = 1 / (xp.exp(exponent) + 1)\n",
    "    window_topG_fixed_max[(ms < mn) | (ms > mx)] = 0\n",
    "    return window_topG_fixed_max \n",
    "\n",
    "def extract_mass_parameters_topG_fixed_max(parameters):\n",
    "    \"\"\"extract the parameters of the mass distribution hyperparameters used in\n",
    "    T&T18 from either a list or dictionary.\"\"\"\n",
    "    if isinstance(parameters, list):\n",
    "        return parameters\n",
    "    elif isinstance(parameters, dict):\n",
    "        keys = ['alpha', 'mmin', 'lam', 'mpp',\n",
    "                'sigpp', 'delta_m']\n",
    "        return [parameters[key] for key in keys]\n",
    "\n",
    "hp_priors_turn_on_pow_G_fixed_max = dict(alpha=Uniform(-5, 25, 'alpha', '$\\\\alpha$'),\n",
    "                 mmin=Uniform(0.9, 1.5, 'mmin', '$mmin$'),\n",
    "                lam=Uniform(0.0, 1, 'lam', '$\\\\lambda$'),\n",
    "                 mpp=Uniform(0.9, 2.9, 'mpp', '$mpp$'),\n",
    "                 sigpp=Uniform(0.01, 2, 'sigpp', '$\\\\sigma$'),\n",
    "                delta_m=Uniform(0.01, 1, 'delta', '$\\\\delta$'))\n",
    "#end top + Gaussian with fixed max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9e47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import erf\n",
    "from scipy.stats import beta as beta_dist\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.interpolate import interp1d\n",
    "import bilby\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from bilby.core.prior import Uniform\n",
    "from bilby.core.sampler import run_sampler\n",
    "from bilby.core.prior import LogUniform\n",
    "from bilby.hyper.likelihood import HyperparameterLikelihood\n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "import random\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#####################\n",
    "outdir='test_all_model_hy_outdir'\n",
    "data_exps=np.loadtxt('/home4/yzq/NS_mass/NS_sci/NSmassData/ligo_post/obs_90times5k.txt')\n",
    "data_exp=data_exps[::50]\n",
    "import sys\n",
    "NN=int(len(data_exp)/100)\n",
    "nlive=200\n",
    "mx=100\n",
    "#################################\n",
    "data_df=list()\n",
    "ns_m=abs(data_exp)\n",
    "for i in range(NN):\n",
    "    re=pd.DataFrame(ns_m[i*mx:(i+1)*mx],columns=['mu'])\n",
    "    data_df.append(re)\n",
    "samples = data_df\n",
    "\n",
    "def run_prior(dataset):\n",
    "    return 1/(2.9-0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6058e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin top + Gaussian    \n",
    "def hyper_prior_turn_on_pow_G(dataset, alpha, mmin, mmax,lam, mpp, sigpp, delta_m):\n",
    "    \"\"\"\n",
    "    Identically and independently masses following p(m1) in T&T 2018\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: dict\n",
    "        Dictionary containing NxM arrays, m1_source and m2_source\n",
    "    alpha, mmin, mmax, lam, mpp, sigpp, delta_m: see mass_distribution\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    probability: array-like\n",
    "        Probability of m1, m2 in dataset, shape=(NxM)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The factor of 2 comes from requiring m1>m2\n",
    "    \"\"\"\n",
    "    parameters = dict(\n",
    "        alpha=alpha, mmin=mmin, mmax=mmax,lam=lam, mpp=mpp,\n",
    "        sigpp=sigpp, delta_m=delta_m)\n",
    "    pow_norm_topG = norm_ppow_topG(parameters)\n",
    "    pp_norm_topG = norm_pnorm_topG(parameters)\n",
    "    probability = pmodel1d_topG(dataset['mu'], parameters, pow_norm_topG, pp_norm_topG)\n",
    "    return probability\n",
    "\n",
    "def pmodel1d_topG(ms, parameters, pow_norm_topG, pp_norm_topG):\n",
    "    \"\"\"normalised m1 pdf from T&T 2018\"\"\"\n",
    "    al, mn, mx,lam, mp, sp, delta_m = extract_mass_parameters_topG(parameters)\n",
    "    p_pow_topG = ppow_topG(ms, parameters) / pow_norm_topG\n",
    "    p_norm_topG = pnorm_topG(ms, parameters) / pp_norm_topG\n",
    "    return (1 - lam) * p_pow_topG + lam * p_norm_topG\n",
    "\n",
    "def ppow_topG(ms, parameters):\n",
    "    \"\"\"1d unnormalised powerlaw mass probability with smoothed low-mass end\"\"\"\n",
    "    al, mn, mx,lam, mp, sp, delta_m = extract_mass_parameters_topG(parameters)\n",
    "    return ms**(-al) * window_topG(ms, mn,mx, delta_m)\n",
    "\n",
    "\n",
    "def norm_ppow_topG(parameters):\n",
    "    \"\"\"normalise ppow, requires m1s, an array of m values, and dm, the spacing of\n",
    "    that array\"\"\"\n",
    "    m1s = np.linspace(0.9, mx, 500)\n",
    "    return np.trapz(ppow_topG(m1s, parameters), m1s)\n",
    "\n",
    "\n",
    "def pnorm_topG(ms, parameters):\n",
    "    \"\"\"1d unnormalised normal distribution with low-mass smoothing\"\"\"\n",
    "    al, mn,mx, lam, mp, sp, delta_m = extract_mass_parameters_topG(parameters)\n",
    "    return np.exp(-(ms - mp)**2 / (2 * sp**2)) * window_topG(ms, mn, mx,delta_m)*(mp > (mn + delta_m) )\n",
    "\n",
    "\n",
    "def norm_pnorm_topG(parameters):\n",
    "    \"\"\"normalise pnorm, requires m1s, an array of m values, and dm, the spacing of\n",
    "    that array\"\"\"\n",
    "    m1s = np.linspace(0.9, 2.9, 500)\n",
    "    return np.trapz(pnorm_topG(m1s, parameters), m1s)\n",
    "\n",
    "def window_topG(ms, mn, mx,delta_m):\n",
    "    \"\"\"\n",
    "    Apply a one sided window between mmin and mmin + delta_m to the\n",
    "    mass pdf.\n",
    "    The upper cut off is a step function,\n",
    "    the lower cutoff is a logistic rise over delta_m solar masses.\n",
    "    See T&T18 Eqs 7-8\n",
    "    Note that there is a sign error in that paper.\n",
    "    S = (f(m - mmin, delta_m) + 1)^{-1}\n",
    "    f(m') = delta_m / m' + delta_m / (m' - delta_m)\n",
    "    See also, https://en.wikipedia.org/wiki/Window_function#Planck-taper_window\n",
    "    \"\"\"\n",
    "    window_topG = xp.ones_like(ms)\n",
    "    if delta_m > 0.0:\n",
    "        smoothing_region = (ms >= mn) & (ms < (mn + delta_m))\n",
    "        shifted_mass = ms[smoothing_region] - mn\n",
    "        if shifted_mass.size:\n",
    "            exponent = xp.nan_to_num(\n",
    "                delta_m / shifted_mass + delta_m / (shifted_mass - delta_m)\n",
    "            )\n",
    "            window_topG[smoothing_region] = 1 / (xp.exp(exponent) + 1)\n",
    "    window_topG[(ms < mn) | (ms > mx)] = 0\n",
    "    return window_topG \n",
    "\n",
    "def extract_mass_parameters_topG(parameters):\n",
    "    \"\"\"extract the parameters of the mass distribution hyperparameters used in\n",
    "    T&T18 from either a list or dictionary.\"\"\"\n",
    "    if isinstance(parameters, list):\n",
    "        return parameters\n",
    "    elif isinstance(parameters, dict):\n",
    "        keys = ['alpha', 'mmin','mmax', 'lam', 'mpp',\n",
    "                'sigpp', 'delta_m']\n",
    "        return [parameters[key] for key in keys]\n",
    "\n",
    "hp_priors_turn_on_pow_G = dict(alpha=Uniform(-5, 25, 'alpha', '$\\\\alpha$'),\n",
    "                 mmin=Uniform(0.9, 1.5, 'mmin', '$mmin$'),\n",
    "                 mmax=Uniform(1.5, 2.9, 'mmax', '$mmax$'),\n",
    "                lam=Uniform(0.0, 1, 'lam', '$\\\\lambda$'),\n",
    "                 mpp=Uniform(0.9, 2.9, 'mpp', '$mpp$'),\n",
    "                 sigpp=Uniform(0.01, 2, 'sigpp', '$\\\\sigma$'),\n",
    "                delta_m=Uniform(0.01, 1, 'delta', '$\\\\delta$'))\n",
    "#end top + Gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35fda3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:20 bilby INFO    : Running for label 'top_G_20230228_1', output will be saved to 'test_all_model_hy_outdir'\n",
      "01:20 bilby INFO    : Search parameters:\n",
      "01:20 bilby INFO    :   alpha = Uniform(minimum=-5, maximum=25, name='alpha', latex_label='$\\\\alpha$', unit=None, boundary=None)\n",
      "01:20 bilby INFO    :   mmin = Uniform(minimum=0.9, maximum=1.5, name='mmin', latex_label='$mmin$', unit=None, boundary=None)\n",
      "01:20 bilby INFO    :   mmax = Uniform(minimum=1.5, maximum=2.9, name='mmax', latex_label='$mmax$', unit=None, boundary=None)\n",
      "01:20 bilby INFO    :   lam = Uniform(minimum=0.0, maximum=1, name='lam', latex_label='$\\\\lambda$', unit=None, boundary=None)\n",
      "01:20 bilby INFO    :   mpp = Uniform(minimum=0.9, maximum=2.9, name='mpp', latex_label='$mpp$', unit=None, boundary=None)\n",
      "01:20 bilby INFO    :   sigpp = Uniform(minimum=0.01, maximum=2, name='sigpp', latex_label='$\\\\sigma$', unit=None, boundary=None)\n",
      "01:20 bilby INFO    :   delta_m = Uniform(minimum=0.01, maximum=1, name='delta', latex_label='$\\\\delta$', unit=None, boundary=None)\n",
      "01:20 bilby INFO    : Single likelihood evaluation took 2.680e-03 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:20 bilby INFO    : Using sampler Dynesty with kwargs {'bound': 'multi', 'sample': 'rwalk', 'verbose': True, 'periodic': None, 'reflective': None, 'check_point_delta_t': 600, 'nlive': 200, 'first_update': None, 'walks': 100, 'npdim': None, 'rstate': None, 'queue_size': 80, 'pool': None, 'use_pool': None, 'live_points': None, 'logl_args': None, 'logl_kwargs': None, 'ptform_args': None, 'ptform_kwargs': None, 'enlarge': 1.5, 'bootstrap': None, 'vol_dec': 0.5, 'vol_check': 8.0, 'facc': 0.2, 'slices': 5, 'update_interval': 120, 'print_func': <bound method Dynesty._print_func of <bilby.core.sampler.dynesty.Dynesty object at 0x7fece34fb550>>, 'dlogz': 0.1, 'maxiter': None, 'maxcall': None, 'logl_max': inf, 'add_live': True, 'print_progress': True, 'save_bounds': False, 'n_effective': None, 'maxmcmc': 5000, 'nact': 5}\n",
      "01:20 bilby INFO    : Checkpoint every check_point_delta_t = 60s\n",
      "01:20 bilby INFO    : Using dynesty version 1.0.1\n",
      "01:20 bilby INFO    : Using the bilby-implemented rwalk sample method with ACT estimated walks\n",
      "01:20 bilby INFO    : Setting up multiproccesing pool with 80 processes.\n",
      "01:20 bilby INFO    : Generating initial points from the prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033it [00:47, 25.03it/s, bound:999 nc:545 ncall:2.4e+05 eff:0.9% logz=73.85+/-0.32 dlogz:18.483>0.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:21 bilby INFO    : Run interrupted by signal 2: checkpoint and exit on 130\n",
      "01:21 bilby INFO    : Written checkpoint file test_all_model_hy_outdir/top_G_20230228_1_resume.pickle\n",
      "01:21 bilby INFO    : Starting to close worker pool.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hyper_prior=hyper_prior_turn_on_pow_G\n",
    "hp_likelihood = HyperparameterLikelihood(\n",
    "          posteriors=samples, hyper_prior=hyper_prior,\n",
    "          sampling_prior=run_prior, log_evidences=0, max_samples=mx)\n",
    "\n",
    "hp_priors = hp_priors_turn_on_pow_G\n",
    "\n",
    "    # And run sampler\n",
    "result = run_sampler(\n",
    "           likelihood=hp_likelihood, priors=hp_priors, sampler='dynesty', nlive=nlive,\n",
    "           use_ratio=False, outdir=outdir, npool=80, label='top_G_20230228_2',check_point_delta_t = 60,\n",
    "           verbose=True, clean=True)\n",
    "result.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6fd73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilby069",
   "language": "python",
   "name": "bilby069"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
